{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858c4122-516a-4100-b191-2521da2f103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be0476f2-17c1-47d6-99bd-3e77a955cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find('span', attrs={'id':'productTitle'}).text.strip()\n",
    "    except AttributeError:\n",
    "        title = \"\"\n",
    "    return title\n",
    "\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find('span', attrs={'class':'a-price a-text-price a-size-medium apexPriceToPay'}).span.text\n",
    "    except AttributeError:            \n",
    "        price = \"\"\n",
    "    return price\n",
    "\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find('span', attrs={'class':'a-size-base a-color-base'}).text\n",
    "    except AttributeError:\n",
    "        rating = \"\"\n",
    "    return rating\n",
    "\n",
    "\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find('span', attrs={'id':'acrCustomerReviewText'}).text\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\n",
    "    return review_count\n",
    "\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find('span', attrs={'class':'a-size-base a-color-price a-text-bold'}).text\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\n",
    "    return available\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33af074b-a9f7-49ae-9b4a-3509aba26396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AllahRakha\\AppData\\Local\\Temp\\ipykernel_11472\\4128810479.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  amazon_df['titles'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# MIAN FUNCTION\n",
    "if __name__ == '__main__':\n",
    "    # CREDENTIALS\n",
    "    URL = \"https://www.amazon.com/s?k=playstation+5&crid=Q4PL43VKZ4MP&sprefix=playst%2Caps%2C574&ref=nb_sb_ss_pltr-xclick_1_6\"\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "    }\n",
    "\n",
    "    # MAKING REQUEST\n",
    "    webpage = requests.get(URL, headers=HEADERS).text\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    \n",
    "    # LINKS (ANCHOR TAGS)\n",
    "    links = soup.find_all('a', attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "    # NAVIGATING LINKS TO GET HREF LINKS\n",
    "    links_list = []\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "\n",
    "    # LOOPING LINKS_LIST TO GET DETAILS\n",
    "    dictionary_info = {'titles': [], 'prices': [], 'ratings': [], 'reviews': [], 'availability': [],}\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get('https://www.amazon.com'+ link, headers=HEADERS).content # OR .content\n",
    "        new_soup = BeautifulSoup(new_webpage, 'lxml')\n",
    "        # Filling Information\n",
    "        dictionary_info['titles'].append(get_title(new_soup))\n",
    "        dictionary_info['prices'].append(get_price(new_soup))\n",
    "        dictionary_info['ratings'].append(get_rating(new_soup))\n",
    "        dictionary_info['reviews'].append(get_review_count(new_soup))\n",
    "        dictionary_info['availability'].append(get_availability(new_soup))\n",
    "    amazon_df = pd.DataFrame.from_dict(dictionary_info)\n",
    "    amazon_df['titles'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['titles'])\n",
    "    amazon_df.to_csv('amazon_data.csv', header=True, index=False)\n",
    "\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
